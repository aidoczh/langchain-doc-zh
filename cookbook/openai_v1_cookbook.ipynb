{"cells":[{"cell_type":"markdown","id":"f970f757-ec76-4bf0-90cd-a2fb68b945e3","metadata":{},"source":["# 探索 OpenAI V1 功能\n","\n","在 11.06.23，OpenAI 发布了许多新功能，并将他们的 Python SDK 升级到了 1.0.0 版本。本笔记本展示了新功能以及如何在 LangChain 中使用它们。"]},{"cell_type":"code","execution_count":null,"id":"ee897729-263a-4073-898f-bb4cf01ed829","metadata":{},"outputs":[],"source":["# 需要安装 openai>=1.1.0, langchain>=0.0.335, langchain-experimental>=0.0.39\n","!pip install -U openai langchain langchain-experimental\n","这段代码是用来安装指定版本的 openai、langchain 和 langchain-experimental 包的。"]},{"cell_type":"code","execution_count":1,"id":"c3e067ce-7a43-47a7-bc89-41f1de4cf136","metadata":{},"outputs":[],"source":["# 导入所需模块\n","from langchain_core.messages import HumanMessage, SystemMessage\n","from langchain_openai import ChatOpenAI"]},{"cell_type":"markdown","id":"fa7e7e95-90a1-4f73-98fe-10c4b4e0951b","metadata":{},"source":["## [视觉](https://platform.openai.com/docs/guides/vision)\n","\n","OpenAI发布了多模态模型，可以将文本序列和图像作为输入。"]},{"cell_type":"code","execution_count":2,"id":"1c8c3965-d3c9-4186-b5f3-5e67855ef916","metadata":{},"outputs":[{"data":{"text/plain":["AIMessage(content='The image appears to be a diagram representing the architecture or components of a software system or framework related to language processing, possibly named LangChain or associated with a project or product called LangChain, based on the prominent appearance of that term. The diagram is organized into several layers or aspects, each containing various elements or modules:\\n\\n1. **Protocol**: This may be the foundational layer, which includes \"LCEL\" and terms like parallelization, fallbacks, tracing, batching, streaming, async, and composition. These seem related to communication and execution protocols for the system.\\n\\n2. **Integrations Components**: This layer includes \"Model I/O\" with elements such as the model, output parser, prompt, and example selector. It also has a \"Retrieval\" section with a document loader, retriever, embedding model, vector store, and text splitter. Lastly, there\\'s an \"Agent Tooling\" section. These components likely deal with the interaction with external data, models, and tools.\\n\\n3. **Application**: The application layer features \"LangChain\" with chains, agents, agent executors, and common application logic. This suggests that the system uses a modular approach with chains and agents to process language tasks.\\n\\n4. **Deployment**: This contains \"Lang')"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# 导入ChatOpenAI类\n","from openai import ChatOpenAI, HumanMessage\n","\n","# 创建ChatOpenAI实例，指定模型为\"gpt-4-vision-preview\"，最大token数为256\n","chat = ChatOpenAI(model=\"gpt-4-vision-preview\", max_tokens=256)\n","\n","# 调用invoke方法，传入HumanMessage实例作为参数\n","chat.invoke(\n","    [\n","        HumanMessage(\n","            content=[\n","                {\"type\": \"text\", \"text\": \"What is this image showing\"},  # 询问图片展示的内容\n","                {\n","                    \"type\": \"image_url\",  # 指定消息类型为图片链接\n","                    \"image_url\": {\n","                        \"url\": \"https://raw.githubusercontent.com/langchain-ai/langchain/master/docs/static/img/langchain_stack.png\",  # 图片链接\n","                        \"detail\": \"auto\",  # 图片细节自动处理\n","                    },\n","                },\n","            ]\n","        )\n","    ]\n",")"]},{"cell_type":"markdown","id":"210f8248-fcf3-4052-a4a3-0684e08f8785","metadata":{},"source":["## [OpenAI助手](https://platform.openai.com/docs/assistants/overview)\n","\n","> Assistants API允许您在自己的应用程序中构建AI助手。助手具有指令，并可以利用模型、工具和知识来回答用户的查询。助手API目前支持三种类型的工具：代码解释器、检索和函数调用。\n","\n","您可以使用OpenAI工具或自定义工具与OpenAI助手进行交互。当仅使用OpenAI工具时，您可以直接调用助手并获得最终答案。当使用自定义工具时，您可以使用内置的AgentExecutor运行助手和工具执行循环，或者轻松编写自己的执行器。\n","\n","下面我们展示了与助手交互的不同方式。作为一个简单的例子，让我们构建一个能够编写和运行代码的数学导师。"]},{"cell_type":"markdown","id":"318da28d-4cec-42ab-ae3e-76d95bb34fa5","metadata":{},"source":["### 仅使用OpenAI工具\n","\n"]},{"cell_type":"code","execution_count":1,"id":"a9064bbe-d9f7-4a29-a7b3-73933b3197e7","metadata":{},"outputs":[],"source":["# 导入OpenAIAssistantRunnable类\n","from langchain.agents.openai_assistant import OpenAIAssistantRunnable"]},{"cell_type":"code","execution_count":2,"id":"7a20a008-49ac-46d2-aa26-b270118af5ea","metadata":{},"outputs":[{"data":{"text/plain":["[ThreadMessage(id='msg_g9OJv0rpPgnc3mHmocFv7OVd', assistant_id='asst_hTwZeNMMphxzSOqJ01uBMsJI', content=[MessageContentText(text=Text(annotations=[], value='The result of \\\\(10 - 4^{2.7}\\\\) is approximately \\\\(-32.224\\\\).'), type='text')], created_at=1699460600, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_nBIT7SiAwtUfSCTrQNSPLOfe', thread_id='thread_14n4GgXwxgNL0s30WJW5F6p0')]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# 创建一个OpenAIAssistantRunnable对象，用于创建一个助手\n","interpreter_assistant = OpenAIAssistantRunnable.create_assistant(\n","    name=\"langchain assistant\",  # 设置助手的名称为\"langchain assistant\"\n","    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",  # 设置助手的指导说明\n","    tools=[{\"type\": \"code_interpreter\"}],  # 设置助手的工具为代码解释器\n","    model=\"gpt-4-1106-preview\",  # 设置助手使用的模型为\"gpt-4-1106-preview\"\n",")\n","\n","# 调用助手来处理输入内容\"What's 10 - 4 raised to the 2.7\"\n","output = interpreter_assistant.invoke({\"content\": \"What's 10 - 4 raised to the 2.7\"})\n","\n","# 输出助手处理后的结果\n","output"]},{"cell_type":"markdown","id":"a8ddd181-ac63-4ab6-a40d-a236120379c1","metadata":{},"source":["### 作为一个拥有任意工具的LangChain代理\n","\n","现在让我们使用我们自己的工具来重新创建这个功能。在这个例子中，我们将使用[E2B沙盒运行时工具](https://e2b.dev/docs?ref=landing-page-get-started)。"]},{"cell_type":"code","execution_count":null,"id":"ee4cc355-f2d6-4c51-bcf7-f502868357d3","metadata":{},"outputs":[],"source":["# 导入所需的库\n","!pip install e2b duckduckgo-search"]},{"cell_type":"code","execution_count":3,"id":"48681ac7-b267-48d4-972c-8a7df8393a21","metadata":{},"outputs":[],"source":["from langchain.tools import DuckDuckGoSearchRun, E2BDataAnalysisTool\n","\n","tools = [E2BDataAnalysisTool(api_key=\"...\"), DuckDuckGoSearchRun()]"]},{"cell_type":"code","execution_count":4,"id":"1c01dd79-dd3e-4509-a2e2-009a7f99f16a","metadata":{},"outputs":[],"source":["# 导入所需的库\n","from openai import OpenAIAssistantRunnable\n","\n","# 创建一个名为 \"langchain assistant e2b tool\" 的助手\n","# 指定助手的说明为 \"You are a personal math tutor. Write and run code to answer math questions. You can also search the internet.\"\n","# 指定助手的工具为 tools\n","# 指定助手的模型为 \"gpt-4-1106-preview\"\n","# 将助手设置为代理模式\n","agent = OpenAIAssistantRunnable.create_assistant(\n","    name=\"langchain assistant e2b tool\",\n","    instructions=\"You are a personal math tutor. Write and run code to answer math questions. You can also search the internet.\",\n","    tools=tools,\n","    model=\"gpt-4-1106-preview\",\n","    as_agent=True,\n",")"]},{"cell_type":"markdown","id":"1ac71d8b-4b4b-4f98-b826-6b3c57a34166","metadata":{},"source":["#### 使用AgentExecutor"]},{"cell_type":"code","execution_count":5,"id":"1f137f94-801f-4766-9ff5-2de9df5e8079","metadata":{},"outputs":[{"data":{"text/plain":["{'content': \"What's the weather in SF today divided by 2.7\",\n"," 'output': \"The weather in San Francisco today is reported to have temperatures as high as 66 °F. To get the temperature divided by 2.7, we will calculate that:\\n\\n66 °F / 2.7 = 24.44 °F\\n\\nSo, when the high temperature of 66 °F is divided by 2.7, the result is approximately 24.44 °F. Please note that this doesn't have a meteorological meaning; it's purely a mathematical operation based on the given temperature.\"}"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from langchain.agents import AgentExecutor\n","\n","agent_executor = AgentExecutor(agent=agent, tools=tools)\n","agent_executor.invoke({\"content\": \"What's the weather in SF today divided by 2.7\"})"]},{"cell_type":"markdown","id":"2d0a0b1d-c1b3-4b50-9dce-1189b51a6206","metadata":{},"source":["#### 自定义执行"]},{"cell_type":"code","execution_count":6,"id":"c0475fa7-b6c1-4331-b8e2-55407466c724","metadata":{},"outputs":[],"source":["# 创建一个OpenAIAssistantRunnable对象，代表一个可以运行的助手\n","agent = OpenAIAssistantRunnable.create_assistant(\n","    name=\"langchain assistant e2b tool\",  # 设置助手的名称为\"langchain assistant e2b tool\"\n","    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",  # 设置助手的指示为\"你是一个个人数学辅导老师。编写并运行代码来回答数学问题。\"\n","    tools=tools,  # 设置助手的工具\n","    model=\"gpt-4-1106-preview\",  # 设置助手使用的模型为\"gpt-4-1106-preview\"\n","    as_agent=True,  # 将助手设置为代理模式\n",")"]},{"cell_type":"code","execution_count":7,"id":"b76cb669-6aba-4827-868f-00aa960026f2","metadata":{},"outputs":[],"source":["from langchain_core.agents import AgentFinish\n","\n","\n","def execute_agent(agent, tools, input):\n","    # 创建一个工具映射字典，将工具名称映射到工具对象\n","    tool_map = {tool.name: tool for tool in tools}\n","    # 调用代理的invoke方法，并将输入作为参数传入\n","    response = agent.invoke(input)\n","    # 当响应不是AgentFinish类型时，循环执行以下代码块\n","    while not isinstance(response, AgentFinish):\n","        # 创建一个工具输出列表\n","        tool_outputs = []\n","        # 遍历响应中的每个动作\n","        for action in response:\n","            # 调用对应工具的invoke方法，并将动作的工具输入作为参数传入\n","            tool_output = tool_map[action.tool].invoke(action.tool_input)\n","            # 打印工具名称、工具输入、工具输出\n","            print(action.tool, action.tool_input, tool_output, end=\"\\n\\n\")\n","            # 将工具输出和工具调用ID添加到工具输出列表中\n","            tool_outputs.append(\n","                {\"output\": tool_output, \"tool_call_id\": action.tool_call_id}\n","            )\n","        # 调用代理的invoke方法，并将工具输出、运行ID和线程ID作为参数传入\n","        response = agent.invoke(\n","            {\n","                \"tool_outputs\": tool_outputs,\n","                \"run_id\": action.run_id,\n","                \"thread_id\": action.thread_id,\n","            }\n","        )\n","\n","    # 返回响应\n","    return response"]},{"cell_type":"code","execution_count":8,"id":"7946116a-b82f-492e-835e-ca958a8949a5","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["e2b_data_analysis {'python_code': 'print(10 - 4 ** 2.7)'} {\"stdout\": \"-32.22425314473263\", \"stderr\": \"\", \"artifacts\": []}\n","\n","\\( 10 - 4^{2.7} \\) is approximately \\(-32.22425314473263\\).\n"]}],"source":["# 调用execute_agent函数执行代理\n","response = execute_agent(agent, tools, {\"content\": content})\n","\n","# 打印输出结果\n","print(response.return_values[\"output\"])"]},{"cell_type":"code","execution_count":9,"id":"f2744a56-9f4f-4899-827a-fa55821c318c","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["e2b_data_analysis {'python_code': 'result = 10 - 4 ** 2.7\\nprint(result + 17.241)'} {\"stdout\": \"-14.983253144732629\", \"stderr\": \"\", \"artifacts\": []}\n","\n","When you add \\( 17.241 \\) to \\( 10 - 4^{2.7} \\), the result is approximately \\( -14.98325314473263 \\).\n"]}],"source":["# 调用 execute_agent 函数，传入 agent, tools 和参数字典\n","next_response = execute_agent(\n","    agent, tools, {\"content\": \"now add 17.241\", \"thread_id\": response.thread_id}\n",")\n","# 打印 next_response 的 return_values 字典中的 \"output\" 值\n","print(next_response.return_values[\"output\"])"]},{"cell_type":"markdown","id":"71c34763-d1e7-4b9a-a9d7-3e4cc0dfc2c4","metadata":{},"source":["## [JSON 模式](https://platform.openai.com/docs/guides/text-generation/json-mode)\n","\n","将模型限制为仅生成有效的 JSON。请注意，您必须包含一条系统消息，其中包含使用 JSON 的说明，以使此模式正常工作。\n","\n","仅适用于某些模型。"]},{"cell_type":"code","execution_count":null,"id":"db6072c4-f3f3-415d-872b-71ea9f3c02bb","metadata":{},"outputs":[],"source":["# 创建一个ChatOpenAI对象，使用\"gpt-3.5-turbo-1106\"模型\n","chat = ChatOpenAI(model=\"gpt-3.5-turbo-1106\").bind(\n","    response_format={\"type\": \"json_object\"}\n",")\n","\n","# 调用chat对象的invoke方法，传入包含SystemMessage和HumanMessage的列表作为参数\n","output = chat.invoke(\n","    [\n","        SystemMessage(\n","            content=\"Extract the 'name' and 'origin' of any companies mentioned in the following statement. Return a JSON list.\"\n","        ),\n","        HumanMessage(\n","            content=\"Google was founded in the USA, while Deepmind was founded in the UK\"\n","        ),\n","    ]\n",")\n","# 打印输出内容\n","print(output.content)"]},{"cell_type":"code","execution_count":null,"id":"08e00ccf-b991-4249-846b-9500a0ccbfa0","metadata":{},"outputs":[],"source":["import json\n","\n","# 使用json.loads()函数将output.content解析为JSON格式的数据\n","json.loads(output.content)"]},{"cell_type":"markdown","id":"aa9a94d9-4319-4ab7-a979-c475ce6b5f50","metadata":{},"source":["## [系统指纹](https://platform.openai.com/docs/guides/text-generation/reproducible-outputs)\n","\n","OpenAI有时会以影响输出的方式更改模型配置。每当发生这种情况时，与生成相关联的系统指纹将会改变。"]},{"cell_type":"code","execution_count":null,"id":"1281883c-bf8f-4665-89cd-4f33ccde69ab","metadata":{},"outputs":[],"source":["\n","\n","# 创建ChatOpenAI对象，指定模型为\"gpt-3.5-turbo-1106\"\n","chat = ChatOpenAI(model=\"gpt-3.5-turbo-1106\")\n","\n","# 调用generate方法生成对话\n","output = chat.generate(\n","    [\n","        [\n","            SystemMessage(\n","                content=\"Extract the 'name' and 'origin' of any companies mentioned in the following statement. Return a JSON list.\"\n","            ),\n","            HumanMessage(\n","                content=\"Google was founded in the USA, while Deepmind was founded in the UK\"\n","            ),\n","        ]\n","    ]\n",")\n","\n","# 打印生成的输出\n","print(output.llm_output)"]},{"cell_type":"markdown","id":"aa6565be-985d-4127-848e-c3bca9d7b434","metadata":{},"source":["\n","## Azure类的重大变化\n","\n","OpenAI V1重写了他们的客户端，并将Azure和OpenAI客户端分开。这导致在使用OpenAI V1时，LangChain接口发生了一些变化。\n","\n","重大变化：\n","- 要在OpenAI V1中使用Azure嵌入，您需要使用新的`AzureOpenAIEmbeddings`，而不是现有的`OpenAIEmbeddings`。在使用Azure与`openai<1`时，`OpenAIEmbeddings`仍然有效。\n","```python\n","from langchain_openai import AzureOpenAIEmbeddings\n","```\n","\n","\n","推荐更改：\n","- 当使用`AzureChatOpenAI`或`AzureOpenAI`时，如果传入Azure端点（例如https://example-resource.azure.openai.com/），应该通过`azure_endpoint`参数或`AZURE_OPENAI_ENDPOINT`来指定。目前我们仍然通过`openai_api_base`/`base_url`或环境变量`OPENAI_API_BASE`来指定这一点，但不应该依赖于此。\n","- 当使用Azure聊天或嵌入模型时，通过`openai_api_key`参数或`AZURE_OPENAI_API_KEY`参数传入API密钥。目前我们仍然通过`OPENAI_API_KEY`来指定这一点，但不应该依赖于此。\n"]},{"cell_type":"markdown","id":"49944887-3972-497e-8da2-6d32d44345a9","metadata":{},"source":["## 工具\n","\n","使用工具进行并行函数调用。"]},{"cell_type":"code","execution_count":3,"id":"916292d8-0f89-40a6-af1c-5a1122327de8","metadata":{},"outputs":[{"data":{"text/plain":["[GetCurrentWeather(location='New York, NY', unit='fahrenheit'),\n"," GetCurrentWeather(location='Los Angeles, CA', unit='fahrenheit'),\n"," GetCurrentWeather(location='San Francisco, CA', unit='fahrenheit')]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["from typing import Literal\n","\n","from langchain.output_parsers.openai_tools import PydanticToolsParser\n","from langchain.utils.openai_functions import convert_pydantic_to_openai_tool\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.pydantic_v1 import BaseModel, Field\n","\n","\n","class GetCurrentWeather(BaseModel):\n","    \"\"\"Get the current weather in a location.\"\"\"\n","\n","    location: str = Field(description=\"The city and state, e.g. San Francisco, CA\")\n","    unit: Literal[\"celsius\", \"fahrenheit\"] = Field(\n","        default=\"fahrenheit\", description=\"The temperature unit, default to fahrenheit\"\n","    )\n","\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [(\"system\", \"You are a helpful assistant\"), (\"user\", \"{input}\")]\n",")\n","model = ChatOpenAI(model=\"gpt-3.5-turbo-1106\").bind(\n","    tools=[convert_pydantic_to_openai_tool(GetCurrentWeather)]\n",")\n","chain = prompt | model | PydanticToolsParser(tools=[GetCurrentWeather])\n","\n","chain.invoke({\"input\": \"what's the weather in NYC, LA, and SF\"})"]}],"metadata":{"kernelspec":{"display_name":"poetry-venv","language":"python","name":"poetry-venv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.1"}},"nbformat":4,"nbformat_minor":5}
