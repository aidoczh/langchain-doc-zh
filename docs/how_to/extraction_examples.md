# å¦‚ä½•åœ¨æå–è¿‡ç¨‹ä¸­ä½¿ç”¨å‚è€ƒç¤ºä¾‹

é€šè¿‡æä¾›å‚è€ƒç¤ºä¾‹ç»™è¯­è¨€æ¨¡å‹å¯ä»¥æé«˜æå–çš„è´¨é‡ã€‚

æ•°æ®æå–æ—¨åœ¨ç”Ÿæˆæ–‡æœ¬å’Œå…¶ä»–éç»“æ„åŒ–æˆ–åŠç»“æ„åŒ–æ ¼å¼ä¸­çš„ä¿¡æ¯çš„ç»“æ„åŒ–è¡¨ç¤ºã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œé€šå¸¸ä¼šä½¿ç”¨[å·¥å…·è°ƒç”¨](/docs/concepts#functiontool-calling)è¯­è¨€æ¨¡å‹çš„åŠŸèƒ½ã€‚æœ¬æŒ‡å—æ¼”ç¤ºäº†å¦‚ä½•æ„å»ºå°‘æ ·æœ¬å·¥å…·è°ƒç”¨ç¤ºä¾‹æ¥å¸®åŠ©å¼•å¯¼æå–å’Œç±»ä¼¼åº”ç”¨çš„è¡Œä¸ºã€‚

:::tip

è™½ç„¶æœ¬æŒ‡å—ä¾§é‡äºå¦‚ä½•åœ¨å·¥å…·è°ƒç”¨æ¨¡å‹ä¸­ä½¿ç”¨ç¤ºä¾‹ï¼Œä½†è¿™ç§æŠ€æœ¯é€šå¸¸é€‚ç”¨ï¼Œå¹¶ä¸”ä¹Ÿé€‚ç”¨äºJSONç­‰æ›´å¤šåŸºäºæç¤ºçš„æŠ€æœ¯ã€‚

:::

LangChainåœ¨ä»åŒ…å«å·¥å…·è°ƒç”¨çš„è¯­è¨€æ¨¡å‹æ¶ˆæ¯ä¸­å®ç°äº†[tool-callå±æ€§](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.ai.AIMessage.html#langchain_core.messages.ai.AIMessage.tool_calls)ã€‚æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…æˆ‘ä»¬çš„[å·¥å…·è°ƒç”¨æŒ‡å—](/docs/how_to/tool_calling)ã€‚ä¸ºäº†æ„å»ºæ•°æ®æå–çš„å‚è€ƒç¤ºä¾‹ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªåŒ…å«ä»¥ä¸‹åºåˆ—çš„èŠå¤©å†å²è®°å½•ï¼š

- åŒ…å«ç¤ºä¾‹è¾“å…¥çš„[HumanMessage](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.human.HumanMessage.html)

- åŒ…å«ç¤ºä¾‹å·¥å…·è°ƒç”¨çš„[AIMessage](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.ai.AIMessage.html)

- åŒ…å«ç¤ºä¾‹å·¥å…·è¾“å‡ºçš„[ToolMessage](https://api.python.langchain.com/en/latest/messages/langchain_core.messages.tool.ToolMessage.html)

LangChainé‡‡ç”¨äº†è¿™ç§å°†å·¥å…·è°ƒç”¨ç»“æ„åŒ–ä¸ºLLMæ¨¡å‹æä¾›è€…ä¹‹é—´å¯¹è¯çš„çº¦å®šã€‚

é¦–å…ˆï¼Œæˆ‘ä»¬æ„å»ºä¸€ä¸ªåŒ…å«è¿™äº›æ¶ˆæ¯å ä½ç¬¦çš„æç¤ºæ¨¡æ¿ï¼š

```python
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
# å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰æç¤ºï¼Œæä¾›è¯´æ˜å’Œä»»ä½•å…¶ä»–ä¸Šä¸‹æ–‡ã€‚
# 1) æ‚¨å¯ä»¥å°†ç¤ºä¾‹æ·»åŠ åˆ°æç¤ºæ¨¡æ¿ä¸­ä»¥æé«˜æå–è´¨é‡
# 2) å¼•å…¥å…¶ä»–å‚æ•°ä»¥è€ƒè™‘ä¸Šä¸‹æ–‡ï¼ˆä¾‹å¦‚ï¼ŒåŒ…æ‹¬ä»ä¸­æå–æ–‡æœ¬çš„æ–‡æ¡£çš„å…ƒæ•°æ®ï¼‰
prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            "You are an expert extraction algorithm. "
            "Only extract relevant information from the text. "
            "If you do not know the value of an attribute asked "
            "to extract, return null for the attribute's value.",
        ),
        # â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“â†“
        MessagesPlaceholder("examples"),  # <-- EXAMPLES!
        # â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘â†‘
        ("human", "{text}"),
    ]
)
```

æµ‹è¯•ä¸€ä¸‹è¿™ä¸ªæ¨¡æ¿ï¼š

```python
from langchain_core.messages import (
    HumanMessage,
)
prompt.invoke(
    {"text": "this is some text", "examples": [HumanMessage(content="testing 1 2 3")]}
)
```

```output
ChatPromptValue(messages=[SystemMessage(content="You are an expert extraction algorithm. Only extract relevant information from the text. If you do not know the value of an attribute asked to extract, return null for the attribute's value."), HumanMessage(content='testing 1 2 3'), HumanMessage(content='this is some text')])
```

## å®šä¹‰æ¨¡å¼

è®©æˆ‘ä»¬é‡ç”¨[æå–æ•™ç¨‹](/docs/tutorials/extraction)ä¸­çš„äººç‰©æ¨¡å¼ã€‚

```python
from typing import List, Optional
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_openai import ChatOpenAI
class Person(BaseModel):
    """å…³äºä¸€ä¸ªäººçš„ä¿¡æ¯ã€‚"""
    # ^ Personå®ä½“çš„æ–‡æ¡£å­—ç¬¦ä¸²ã€‚
    # è¿™ä¸ªæ–‡æ¡£å­—ç¬¦ä¸²ä½œä¸ºPersonæ¨¡å¼çš„æè¿°å‘é€ç»™LLMï¼Œå®ƒå¯ä»¥å¸®åŠ©æé«˜æå–ç»“æœã€‚
    # æ³¨æ„ï¼š
    # 1. æ¯ä¸ªå­—æ®µéƒ½æ˜¯`optional`çš„ï¼Œè¿™å…è®¸æ¨¡å‹æ‹’ç»æå–å®ƒï¼
    # 2. æ¯ä¸ªå­—æ®µéƒ½æœ‰ä¸€ä¸ª`description`ï¼Œè¿™ä¸ªæè¿°è¢«LLMä½¿ç”¨ã€‚
    # æœ‰ä¸€ä¸ªå¥½çš„æè¿°å¯ä»¥å¸®åŠ©æé«˜æå–ç»“æœã€‚
    name: Optional[str] = Field(..., description="äººçš„å§“å")
    hair_color: Optional[str] = Field(
        ..., description="å¦‚æœå·²çŸ¥ï¼Œäººçš„çœ¼ç›é¢œè‰²"
    )
    height_in_meters: Optional[str] = Field(..., description="ä»¥ç±³ä¸ºå•ä½çš„èº«é«˜")
class Data(BaseModel):
    """å…³äºäººçš„æå–æ•°æ®ã€‚"""
    # åˆ›å»ºä¸€ä¸ªæ¨¡å‹ï¼Œä»¥ä¾¿æˆ‘ä»¬å¯ä»¥æå–å¤šä¸ªå®ä½“ã€‚
    people: List[Person]
```

## å®šä¹‰å‚è€ƒç¤ºä¾‹

ç¤ºä¾‹å¯ä»¥å®šä¹‰ä¸ºè¾“å…¥-è¾“å‡ºå¯¹çš„åˆ—è¡¨ã€‚

æ¯ä¸ªç¤ºä¾‹åŒ…å«ä¸€ä¸ªç¤ºä¾‹`input`æ–‡æœ¬å’Œä¸€ä¸ªç¤ºä¾‹`output`ï¼Œæ˜¾ç¤ºåº”ä»æ–‡æœ¬ä¸­æå–çš„å†…å®¹ã€‚

:::important

è¿™æœ‰ç‚¹å¤æ‚ï¼Œæ‰€ä»¥å¯ä»¥è·³è¿‡ã€‚

ç¤ºä¾‹çš„æ ¼å¼éœ€è¦ä¸ä½¿ç”¨çš„APIåŒ¹é…ï¼ˆä¾‹å¦‚ï¼Œå·¥å…·è°ƒç”¨æˆ–JSONæ¨¡å¼ç­‰ï¼‰ã€‚

åœ¨è¿™é‡Œï¼Œæ ¼å¼åŒ–çš„ç¤ºä¾‹å°†ä¸å·¥å…·è°ƒç”¨APIæœŸæœ›çš„æ ¼å¼åŒ¹é…ï¼Œå› ä¸ºæˆ‘ä»¬æ­£åœ¨ä½¿ç”¨å®ƒã€‚

:::

```python
import uuid
from typing import Dict, List, TypedDict
from langchain_core.messages import (
    AIMessage,
    BaseMessage,
    HumanMessage,
    SystemMessage,
    ToolMessage,
)
from langchain_core.pydantic_v1 import BaseModel, Field
class Example(TypedDict):
    """ä¸€ä¸ªç”±æ–‡æœ¬è¾“å…¥å’Œé¢„æœŸå·¥å…·è°ƒç”¨ç»„æˆçš„ç¤ºä¾‹è¡¨ç¤ºã€‚
    å¯¹äºæå–ï¼Œå·¥å…·è°ƒç”¨è¢«è¡¨ç¤ºä¸º pydantic æ¨¡å‹çš„å®ä¾‹ã€‚
    """
    input: str  # è¿™æ˜¯ç¤ºä¾‹æ–‡æœ¬
    tool_calls: List[BaseModel]  # åº”è¯¥è¢«æå–çš„ pydantic æ¨¡å‹å®ä¾‹
def tool_example_to_messages(example: Example) -> List[BaseMessage]:
    """å°†ç¤ºä¾‹è½¬æ¢ä¸ºå¯ä»¥è¾“å…¥åˆ° LLM ä¸­çš„æ¶ˆæ¯åˆ—è¡¨ã€‚
    è¿™æ®µä»£ç æ˜¯ä¸€ä¸ªé€‚é…å™¨ï¼Œå°†æˆ‘ä»¬çš„ç¤ºä¾‹è½¬æ¢ä¸ºå¯ä»¥è¾“å…¥åˆ°èŠå¤©æ¨¡å‹ä¸­çš„æ¶ˆæ¯åˆ—è¡¨ã€‚
    æ¯ä¸ªç¤ºä¾‹çš„æ¶ˆæ¯åˆ—è¡¨å¯¹åº”äºï¼š
    1) HumanMessage: åŒ…å«åº”ä»ä¸­æå–å†…å®¹çš„å†…å®¹ã€‚
    2) AIMessage: åŒ…å«æ¨¡å‹ä¸­æå–çš„ä¿¡æ¯
    3) ToolMessage: åŒ…å«å¯¹æ¨¡å‹çš„ç¡®è®¤ï¼Œæ¨¡å‹æ­£ç¡®è¯·æ±‚äº†ä¸€ä¸ªå·¥å…·ã€‚
    éœ€è¦ ToolMessage æ˜¯å› ä¸ºä¸€äº›èŠå¤©æ¨¡å‹æ˜¯é’ˆå¯¹ä»£ç†è€Œä¸æ˜¯æå–ç”¨ä¾‹è¿›è¡Œäº†è¶…ä¼˜åŒ–ã€‚
    """
    messages: List[BaseMessage] = [HumanMessage(content=example["input"])]
    tool_calls = []
    for tool_call in example["tool_calls"]:
        tool_calls.append(
            {
                "id": str(uuid.uuid4()),
                "args": tool_call.dict(),
                # å‡½æ•°åç›®å‰å¯¹åº”äº pydantic æ¨¡å‹çš„åç§°
                # è¿™åœ¨ API ä¸­æ˜¯éšå«çš„ï¼Œ
                # ä¼šéšç€æ—¶é—´çš„æ¨ç§»è€Œæ”¹è¿›ã€‚
                "name": tool_call.__class__.__name__,
            },
        )
    messages.append(AIMessage(content="", tool_calls=tool_calls))
    tool_outputs = example.get("tool_outputs") or [
        "You have correctly called this tool."
    ] * len(tool_calls)
    for output, tool_call in zip(tool_outputs, tool_calls):
        messages.append(ToolMessage(content=output, tool_call_id=tool_call["id"]))
    return messages
examples = [
    (
        "The ocean is vast and blue. It's more than 20,000 feet deep. There are many fish in it.",
        Person(name=None, height_in_meters=None, hair_color=None),
    ),
    (
        "Fiona traveled far from France to Spain.",
        Person(name="Fiona", height_in_meters=None, hair_color=None),
    ),
]
messages = []
for text, tool_call in examples:
    messages.extend(
        tool_example_to_messages({"input": text, "tool_calls": [tool_call]})
    )
```

è®©æˆ‘ä»¬æµ‹è¯•ä¸€ä¸‹æç¤º

```python
example_prompt = prompt.invoke({"text": "this is some text", "examples": messages})
for message in example_prompt.messages:
    print(f"{message.type}: {message}")
```

```output
system: content="You are an expert extraction algorithm. Only extract relevant information from the text. If you do not know the value of an attribute asked to extract, return null for the attribute's value."
human: content="The ocean is vast and blue. It's more than 20,000 feet deep. There are many fish in it."
ai: content='' tool_calls=[{'name': 'Person', 'args': {'name': None, 'hair_color': None, 'height_in_meters': None}, 'id': 'b843ba77-4c9c-48ef-92a4-54e534f24521'}]
tool: content='You have correctly called this tool.' tool_call_id='b843ba77-4c9c-48ef-92a4-54e534f24521'
human: content='Fiona traveled far from France to Spain.'
ai: content='' tool_calls=[{'name': 'Person', 'args': {'name': 'Fiona', 'hair_color': None, 'height_in_meters': None}, 'id': '46f00d6b-50e5-4482-9406-b07bb10340f6'}]
tool: content='You have correctly called this tool.' tool_call_id='46f00d6b-50e5-4482-9406-b07bb10340f6'
human: content='this is some text'
```

## åˆ›å»ºä¸€ä¸ªæå–å™¨

è®©æˆ‘ä»¬é€‰æ‹©ä¸€ä¸ª LLMã€‚å› ä¸ºæˆ‘ä»¬æ­£åœ¨ä½¿ç”¨å·¥å…·è°ƒç”¨ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ”¯æŒå·¥å…·è°ƒç”¨åŠŸèƒ½çš„æ¨¡å‹ã€‚æŸ¥çœ‹[æ­¤è¡¨](/docs/integrations/chat)ä»¥è·å–å¯ç”¨çš„ LLMã€‚

import ChatModelTabs from "@theme/ChatModelTabs";
<ChatModelTabs
  customVarName="llm"
  openaiParams={`model="gpt-4-0125-preview", temperature=0`}
/>

æ ¹æ®æ‰€éœ€çš„æ¨¡å¼ï¼Œä½¿ç”¨ `.with_structured_output` æ–¹æ³•å¯¹æ¨¡å‹è¾“å‡ºè¿›è¡Œç»“æ„åŒ–ï¼Œå‚è€ƒ[æå–æ•™ç¨‹](/docs/tutorials/extraction)ï¼š

```python
runnable = prompt | llm.with_structured_output(
    schema=Data,
    method="function_calling",
    include_raw=False,
)
```

## æ²¡æœ‰ç¤ºä¾‹ ğŸ˜¿

è¯·æ³¨æ„ï¼Œå³ä½¿æ˜¯åŠŸèƒ½å¼ºå¤§çš„æ¨¡å‹ä¹Ÿå¯èƒ½åœ¨**éå¸¸ç®€å•**çš„æµ‹è¯•ç”¨ä¾‹ä¸­å¤±è´¥ï¼

```python
for _ in range(5):
    text = "The solar system is large, but earth has only 1 moon."
    print(runnable.invoke({"text": text, "examples": []}))
```

## å¸¦æœ‰ç¤ºä¾‹çš„æƒ…å†µ ğŸ˜»

å‚è€ƒç¤ºä¾‹æœ‰åŠ©äºä¿®å¤å¤±è´¥çš„æƒ…å†µï¼

```python
for _ in range(5):
    text = "å¤ªé˜³ç³»å¾ˆå¤§ï¼Œä½†åœ°çƒåªæœ‰ä¸€ä¸ªæœˆäº®ã€‚"
    print(runnable.invoke({"text": text, "examples": messages}))
```

```output
people=[]
people=[]
people=[]
people=[]
people=[]
```

è¯·æ³¨æ„ï¼Œæˆ‘ä»¬å¯ä»¥å°†few-shotç¤ºä¾‹è§†ä¸º[Langsmithè·Ÿè¸ª](https://smith.langchain.com/public/4c436bc2-a1ce-440b-82f5-093947542e40/r)ä¸­çš„å·¥å…·è°ƒç”¨ã€‚

æˆ‘ä»¬åœ¨æ­£æ ·æœ¬ä¸Šä¿æŒäº†æ€§èƒ½ï¼š

```python
runnable.invoke(
    {
        "text": "æˆ‘çš„åå­—æ˜¯Harrisonã€‚æˆ‘çš„å¤´å‘æ˜¯é»‘è‰²çš„ã€‚",
        "examples": messages,
    }
)
```

```output
Data(people=[Person(name='Harrison', hair_color='black', height_in_meters=None)])
```