{"cells":[{"cell_type":"markdown","id":"e93283d1","metadata":{},"source":["\n","# 根据上下文长度选择LLM\n","\n","不同的LLM具有不同的上下文长度。作为一个非常直接和实际的例子，OpenAI有两个版本的GPT-3.5-Turbo：一个上下文长度为4k，另一个上下文长度为16k。本笔记展示了如何根据输入在它们之间进行路由。\n"]},{"cell_type":"code","execution_count":24,"id":"cc453450","metadata":{},"outputs":[],"source":["# 导入所需模块\n","from langchain.prompts import PromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.prompt_values import PromptValue\n","from langchain_openai import ChatOpenAI"]},{"cell_type":"code","execution_count":3,"id":"1cec6a10","metadata":{},"outputs":[],"source":["# 导入ChatOpenAI类\n","from openai import ChatOpenAI\n","\n","# 创建一个使用gpt-3.5-turbo模型的short_context_model对象\n","short_context_model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n","\n","# 创建一个使用gpt-3.5-turbo-16k模型的long_context_model对象\n","long_context_model = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")"]},{"cell_type":"code","execution_count":4,"id":"772da153","metadata":{},"outputs":[],"source":["def get_context_length(prompt: PromptValue):\n","    # 将PromptValue对象转换为messages列表\n","    messages = prompt.to_messages()\n","    # 通过short_context_model获取messages中的token数量\n","    tokens = short_context_model.get_num_tokens_from_messages(messages)\n","    # 返回tokens数量\n","    return tokens\n"]},{"cell_type":"code","execution_count":5,"id":"db771e20","metadata":{},"outputs":[],"source":["\n","\n","# 定义一个变量prompt，使用PromptTemplate类的from_template方法，传入一个字符串作为参数\n","# 这个字符串是一个模板，包含了一个占位符{context}，用于接收后续传入的具体内容\n","prompt = PromptTemplate.from_template(\"Summarize this passage: {context}\")"]},{"cell_type":"code","execution_count":20,"id":"af057e2f","metadata":{},"outputs":[],"source":["def choose_model(prompt: PromptValue):\n","    context_len = get_context_length(prompt)  # 获取上下文长度\n","    if context_len < 30:  # 如果上下文长度小于30\n","        print(\"short model\")  # 打印\"短模型\"\n","        return short_context_model  # 返回短上下文模型\n","    else:\n","        print(\"long model\")  # 打印\"长模型\"\n","        return long_context_model  # 返回长上下文模型\n"]},{"cell_type":"code","execution_count":25,"id":"84f3e07d","metadata":{},"outputs":[],"source":["# 创建一个链式操作对象chain\n","chain = prompt | choose_model | StrOutputParser()\n","\n","# prompt是一个输入对象，用于提供输入文本\n","# choose_model是一个模型选择对象，用于选择适合的模型\n","# StrOutputParser是一个字符串输出解析对象，用于解析模型的输出结果\n","\n","# 这行代码将prompt对象传递给choose_model对象，再将choose_model对象的输出传递给StrOutputParser对象\n","# 最终得到一个可以解析模型输出结果的链式操作对象chain"]},{"cell_type":"code","execution_count":26,"id":"d8b14f8f","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["short model\n"]},{"data":{"text/plain":["'The passage mentions that a frog visited a pond.'"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["\n","# 调用chain模块的invoke函数，并传入一个字典作为参数\n","# 字典中包含一个键值对，键为\"context\"，值为\"a frog went to a pond\"\n","chain.invoke({\"context\": \"a frog went to a pond\"})\n","\n"]},{"cell_type":"code","execution_count":27,"id":"70ebd3dd","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["long model\n"]},{"data":{"text/plain":["'The passage describes a frog that moved from one pond to another and perched on a log.'"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["\n","# 调用chain的invoke方法，并传入一个字典作为参数\n","chain.invoke(\n","    {\"context\": \"a frog went to a pond and sat on a log and went to a different pond\"}\n",")"]},{"cell_type":"code","execution_count":null,"id":"a7e29fef","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.1"}},"nbformat":4,"nbformat_minor":5}
